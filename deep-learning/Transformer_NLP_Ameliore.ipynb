{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Transformer pour le NLP : G√©n√©ration de Texte en Fran√ßais \n",
    "\n",
    "Ce notebook enrichit l'architecture Transformer de base avec trois techniques d'optimisation :\n",
    "\n",
    "1. **‚ö° Warmup LR Schedule** - Augmentation progressive du learning rate pour stabiliser l'entra√Ænement\n",
    "2. **üîç Beam Search** - Recherche sophistiqu√©e pour une g√©n√©ration de texte optimale\n",
    "3. **üå°Ô∏è Temperature Tuning** - Contr√¥le de la cr√©ativit√© dans la g√©n√©ration (0.5-1.5)\n",
    "\n",
    "### Pourquoi ces am√©liorations ?\n",
    "\n",
    "- **Warmup** : √âvite la divergence en d√©but d'entra√Ænement avec des gradients instables\n",
    "- **Beam Search** : Explore plusieurs hypoth√®ses en parall√®le au lieu d'un seul chemin\n",
    "- **Temperature** : Permet d'ajuster entre g√©n√©ration conservatrice (0.5) et cr√©ative (1.5)\n",
    "\n",
    "Ces techniques sont utilis√©es dans **tous les LLMs modernes** (GPT, BERT, etc.) !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:37:12.967628: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-05 18:37:13.685349: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-05 18:37:15.914011: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Aucun GPU d√©tect√© - Utilisation du CPU\n",
      "\n",
      "üì¶ TensorFlow version: 2.20.0\n",
      "üì¶ Keras version: 3.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 18:37:16.569327: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Biblioth√®ques principales\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output, HTML, display\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "\n",
    "# TensorFlow et Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback, LearningRateScheduler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Configuration GPU\n",
    "try:\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"‚úÖ GPU(s) d√©tect√©(s): {len(gpus)} - Croissance m√©moire activ√©e\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Aucun GPU d√©tect√© - Utilisation du CPU\")\n",
    "except Exception as e:\n",
    "    print(f\"Configuration GPU: {e}\")\n",
    "\n",
    "# Configuration graphiques\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Reproductibilit√©\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"\\nüì¶ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"üì¶ Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset : Proverbes et Citations Fran√ßais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus √©tendu de textes en fran√ßais (400+ phrases)\n",
    "corpus_francais = [\n",
    "    # Proverbes fran√ßais classiques (50 proverbes)\n",
    "    \"Petit √† petit, l'oiseau fait son nid.\",\n",
    "    \"Qui vivra verra.\",\n",
    "    \"L'habit ne fait pas le moine.\",\n",
    "    \"Pierre qui roule n'amasse pas mousse.\",\n",
    "    \"Tout vient √† point √† qui sait attendre.\",\n",
    "    \"La nuit porte conseil.\",\n",
    "    \"Mieux vaut tard que jamais.\",\n",
    "    \"Il n'y a pas de fum√©e sans feu.\",\n",
    "    \"Les chiens aboient, la caravane passe.\",\n",
    "    \"Chat √©chaud√© craint l'eau froide.\",\n",
    "    \"Qui ne tente rien n'a rien.\",\n",
    "    \"L'argent ne fait pas le bonheur.\",\n",
    "    \"Les jours se suivent et ne se ressemblent pas.\",\n",
    "    \"Il faut battre le fer tant qu'il est chaud.\",\n",
    "    \"Qui s√®me le vent r√©colte la temp√™te.\",\n",
    "    \"Deux pr√©cautions valent mieux qu'une.\",\n",
    "    \"Ventre affam√© n'a point d'oreilles.\",\n",
    "    \"Qui ne risque rien n'a rien.\",\n",
    "    \"Apr√®s la pluie, le beau temps.\",\n",
    "    \"L'union fait la force.\",\n",
    "    \"Les grands esprits se rencontrent.\",\n",
    "    \"Loin des yeux, loin du c≈ìur.\",\n",
    "    \"Qui dort d√Æne.\",\n",
    "    \"La parole est d'argent, le silence est d'or.\",\n",
    "    \"Il n'est jamais trop tard pour bien faire.\",\n",
    "    \"Rira bien qui rira le dernier.\",\n",
    "    \"Tous les chemins m√®nent √† Rome.\",\n",
    "    \"Une hirondelle ne fait pas le printemps.\",\n",
    "    \"Qui aime bien ch√¢tie bien.\",\n",
    "    \"La fin justifie les moyens.\",\n",
    "    \"Tel p√®re, tel fils.\",\n",
    "    \"Comme on fait son lit, on se couche.\",\n",
    "    \"Un tiens vaut mieux que deux tu l'auras.\",\n",
    "    \"Aux innocents les mains pleines.\",\n",
    "    \"Quand le chat n'est pas l√†, les souris dansent.\",\n",
    "    \"Il faut tourner sept fois sa langue dans sa bouche.\",\n",
    "    \"Qui vole un ≈ìuf vole un b≈ìuf.\",\n",
    "    \"√Ä chaque jour suffit sa peine.\",\n",
    "    \"Les petits ruisseaux font les grandes rivi√®res.\",\n",
    "    \"Paris ne s'est pas fait en un jour.\",\n",
    "    \"Tant va la cruche √† l'eau qu'√† la fin elle se casse.\",\n",
    "    \"La faim chasse le loup du bois.\",\n",
    "    \"L'homme propose et Dieu dispose.\",\n",
    "    \"Chose promise, chose due.\",\n",
    "    \"Les absents ont toujours tort.\",\n",
    "    \"La raison du plus fort est toujours la meilleure.\",\n",
    "    \"√Ä bon chat, bon rat.\",\n",
    "    \"Les conseilleurs ne sont pas les payeurs.\",\n",
    "    \"Comparaison n'est pas raison.\",\n",
    "    \"Il ne faut pas vendre la peau de l'ours avant de l'avoir tu√©.\",\n",
    "    \n",
    "    # Citations sur la vie (60 citations)\n",
    "    \"La vie est belle quand on sait la regarder.\",\n",
    "    \"Le savoir est la seule richesse qu'on ne peut pas voler.\",\n",
    "    \"Un sourire co√ªte moins cher que l'√©lectricit√© mais donne autant de lumi√®re.\",\n",
    "    \"Le bonheur n'est pas une destination, c'est une fa√ßon de voyager.\",\n",
    "    \"Chaque jour est une nouvelle chance de changer sa vie.\",\n",
    "    \"La patience est la cl√© de la r√©ussite.\",\n",
    "    \"Les r√™ves sont les graines de la r√©alit√©.\",\n",
    "    \"L'√©chec est le fondement de la r√©ussite.\",\n",
    "    \"Le temps gu√©rit toutes les blessures.\",\n",
    "    \"La v√©rit√© finit toujours par triompher.\",\n",
    "    \"L'amour est plus fort que la haine.\",\n",
    "    \"La connaissance √©claire l'esprit.\",\n",
    "    \"Le travail acharn√© porte ses fruits.\",\n",
    "    \"La curiosit√© est le moteur de la d√©couverte.\",\n",
    "    \"L'honn√™tet√© est toujours r√©compens√©e.\",\n",
    "    \"La simplicit√© est la sophistication supr√™me.\",\n",
    "    \"Le silence est parfois la meilleure r√©ponse.\",\n",
    "    \"L'espoir fait vivre.\",\n",
    "    \"La beaut√© est dans l'≈ìil de celui qui regarde.\",\n",
    "    \"Le voyage est plus important que la destination.\",\n",
    "    \"La libert√© n'a pas de prix.\",\n",
    "    \"L'imagination est plus importante que le savoir.\",\n",
    "    \"La qualit√© vaut mieux que la quantit√©.\",\n",
    "    \"Le pr√©sent est un cadeau pr√©cieux.\",\n",
    "    \"La musique adoucit les m≈ìurs.\",\n",
    "    \"L'√©ducation ouvre toutes les portes.\",\n",
    "    \"La nature est un livre ouvert.\",\n",
    "    \"Le rire est le meilleur des rem√®des.\",\n",
    "    \"La gratitude transforme ce que nous avons en suffisance.\",\n",
    "    \"Le changement est la seule constante.\",\n",
    "    \"La vie commence l√† o√π commence ta zone de confort.\",\n",
    "    \"Chaque instant est un nouveau d√©part.\",\n",
    "    \"La pers√©v√©rance est le chemin du succ√®s.\",\n",
    "    \"Les obstacles sont des opportunit√©s d√©guis√©es.\",\n",
    "    \"Le courage, c'est d'avoir peur et d'avancer quand m√™me.\",\n",
    "    \"La sagesse vient avec l'exp√©rience.\",\n",
    "    \"Le meilleur moment pour planter un arbre √©tait il y a vingt ans.\",\n",
    "    \"Le second meilleur moment est maintenant.\",\n",
    "    \"La confiance en soi est le premier secret du succ√®s.\",\n",
    "    \"Les grandes choses ont de petits commencements.\",\n",
    "    \"L'optimisme est une forme de courage.\",\n",
    "    \"La discipline est le pont entre les objectifs et l'accomplissement.\",\n",
    "    \"Le succ√®s est la somme de petits efforts r√©p√©t√©s jour apr√®s jour.\",\n",
    "    \"La vie est trop courte pour √™tre petite.\",\n",
    "    \"Fais de ta vie un r√™ve et d'un r√™ve une r√©alit√©.\",\n",
    "    \"Le bonheur est une direction, pas un lieu.\",\n",
    "    \"Chaque expert a √©t√© un jour un d√©butant.\",\n",
    "    \"La motivation te fait commencer, l'habitude te fait continuer.\",\n",
    "    \"Le seul moyen de faire du bon travail est d'aimer ce que tu fais.\",\n",
    "    \"La cr√©ativit√© exige le courage de l√¢cher prise sur les certitudes.\",\n",
    "    \"L'action est la cl√© fondamentale de tout succ√®s.\",\n",
    "    \"Le pessimiste voit la difficult√© dans chaque opportunit√©.\",\n",
    "    \"L'optimiste voit l'opportunit√© dans chaque difficult√©.\",\n",
    "    \"La vie est comme une bicyclette, il faut avancer pour ne pas perdre l'√©quilibre.\",\n",
    "    \"Sois le changement que tu veux voir dans le monde.\",\n",
    "    \"Le talent gagne des matchs, mais le travail d'√©quipe gagne des championnats.\",\n",
    "    \"La vraie g√©n√©rosit√© envers l'avenir consiste √† tout donner au pr√©sent.\",\n",
    "    \"L'important n'est pas de convaincre mais de donner √† r√©fl√©chir.\",\n",
    "    \"Le doute est le commencement de la sagesse.\",\n",
    "    \"La perfection est atteinte non pas lorsqu'il n'y a plus rien √† ajouter.\",\n",
    "    \n",
    "    # Phrases sur la nature (50 phrases)\n",
    "    \"Le soleil brille dans le ciel bleu.\",\n",
    "    \"Les oiseaux chantent dans les arbres.\",\n",
    "    \"La pluie tombe doucement sur la terre.\",\n",
    "    \"Le vent souffle √† travers les feuilles.\",\n",
    "    \"Les fleurs poussent au printemps.\",\n",
    "    \"La lune √©claire la nuit √©toil√©e.\",\n",
    "    \"Les vagues d√©ferlent sur le rivage.\",\n",
    "    \"La neige recouvre les montagnes en hiver.\",\n",
    "    \"Les papillons volent de fleur en fleur.\",\n",
    "    \"L'eau de la rivi√®re coule paisiblement.\",\n",
    "    \"Les nuages dansent dans le ciel.\",\n",
    "    \"Le chant du rossignol r√©sonne dans la for√™t.\",\n",
    "    \"Les √©toiles scintillent dans la nuit noire.\",\n",
    "    \"Le parfum des roses embaume le jardin.\",\n",
    "    \"Les feuilles d'automne tombent doucement.\",\n",
    "    \"La ros√©e du matin perle sur l'herbe.\",\n",
    "    \"Le tonnerre gronde au loin.\",\n",
    "    \"L'arc-en-ciel appara√Æt apr√®s l'orage.\",\n",
    "    \"Les abeilles butinent les fleurs sauvages.\",\n",
    "    \"Le cr√©puscule peint le ciel de mille couleurs.\",\n",
    "    \"La mer s'√©tend √† perte de vue.\",\n",
    "    \"Les arbres se balancent sous la brise l√©g√®re.\",\n",
    "    \"Le givre recouvre les branches en hiver.\",\n",
    "    \"Les grenouilles coassent au bord de l'√©tang.\",\n",
    "    \"Le soleil se couche derri√®re les collines.\",\n",
    "    \"Les montagnes se dressent majestueusement.\",\n",
    "    \"La cascade tombe avec fracas.\",\n",
    "    \"Les champignons poussent dans le sous-bois.\",\n",
    "    \"Le brouillard enveloppe la vall√©e.\",\n",
    "    \"Les √©cureuils grimpent aux arbres.\",\n",
    "    \"La temp√™te fait rage sur l'oc√©an.\",\n",
    "    \"Les lucioles illuminent la nuit d'√©t√©.\",\n",
    "    \"Le coucou annonce le retour du printemps.\",\n",
    "    \"Les iris fleurissent au bord de l'eau.\",\n",
    "    \"La pleine lune √©claire le paysage.\",\n",
    "    \"Les hirondelles volent bas avant la pluie.\",\n",
    "    \"Le vent d'automne emporte les feuilles mortes.\",\n",
    "    \"Les bourgeons √©closent au printemps.\",\n",
    "    \"La brume matinale se dissipe lentement.\",\n",
    "    \"Les cigales chantent par les chaudes journ√©es d'√©t√©.\",\n",
    "    \"Le gel dessine des motifs sur les vitres.\",\n",
    "    \"Les nuages s'amoncellent avant l'orage.\",\n",
    "    \"Le vent du nord apporte le froid.\",\n",
    "    \"Les premi√®res gouttes de pluie rafra√Æchissent l'air.\",\n",
    "    \"La nature s'√©veille avec le printemps.\",\n",
    "    \"Les stalactites pendent du toit en hiver.\",\n",
    "    \"Le soleil r√©chauffe la terre.\",\n",
    "    \"Les champs de bl√© ondulent sous le vent.\",\n",
    "    \"La for√™t se pare de ses couleurs d'automne.\",\n",
    "    \"Les marmottes sifflent dans la montagne.\",\n",
    "    \n",
    "    # Phrases sur les actions et valeurs (60 phrases)\n",
    "    \"Il faut toujours croire en ses r√™ves.\",\n",
    "    \"Apprendre est un voyage sans fin.\",\n",
    "    \"Le courage n'est pas l'absence de peur.\",\n",
    "    \"Chaque erreur est une le√ßon pr√©cieuse.\",\n",
    "    \"La pers√©v√©rance m√®ne au succ√®s.\",\n",
    "    \"L'amiti√© est un tr√©sor inestimable.\",\n",
    "    \"Le respect est la base de toute relation.\",\n",
    "    \"La g√©n√©rosit√© enrichit celui qui donne.\",\n",
    "    \"La compassion ouvre les c≈ìurs.\",\n",
    "    \"L'empathie cr√©e des ponts entre les gens.\",\n",
    "    \"La tol√©rance est une vertu essentielle.\",\n",
    "    \"Le pardon lib√®re l'√¢me.\",\n",
    "    \"La bienveillance illumine le monde.\",\n",
    "    \"L'humilit√© est la marque des grands.\",\n",
    "    \"La sinc√©rit√© forge la confiance.\",\n",
    "    \"L'int√©grit√© guide nos actions.\",\n",
    "    \"La fid√©lit√© renforce les liens.\",\n",
    "    \"La loyaut√© est rare et pr√©cieuse.\",\n",
    "    \"La solidarit√© unit les communaut√©s.\",\n",
    "    \"L'entraide fait avancer l'humanit√©.\",\n",
    "    \"La coop√©ration multiplie les forces.\",\n",
    "    \"Le dialogue r√©sout les conflits.\",\n",
    "    \"L'√©coute est un art subtil.\",\n",
    "    \"La communication rapproche les individus.\",\n",
    "    \"La transparence √©tablit la confiance.\",\n",
    "    \"L'authenticit√© attire les autres.\",\n",
    "    \"La modestie sied aux sages.\",\n",
    "    \"La prudence √©vite bien des malheurs.\",\n",
    "    \"La sagesse vient avec l'√¢ge.\",\n",
    "    \"La r√©flexion pr√©c√®de l'action.\",\n",
    "    \"La m√©ditation apaise l'esprit.\",\n",
    "    \"La concentration am√©liore les performances.\",\n",
    "    \"La d√©termination surmonte les obstacles.\",\n",
    "    \"L'ambition pousse √† se d√©passer.\",\n",
    "    \"La volont√© forge le caract√®re.\",\n",
    "    \"La t√©nacit√© vient √† bout de tout.\",\n",
    "    \"La constance m√®ne √† l'excellence.\",\n",
    "    \"La r√©gularit√© engendre le progr√®s.\",\n",
    "    \"L'assiduit√© porte ses fruits.\",\n",
    "    \"Le d√©vouement m√©rite le respect.\",\n",
    "    \"L'engagement inspire les autres.\",\n",
    "    \"La passion anime l'existence.\",\n",
    "    \"L'enthousiasme est contagieux.\",\n",
    "    \"La joie de vivre illumine chaque instant.\",\n",
    "    \"L'optimisme transforme les d√©fis en opportunit√©s.\",\n",
    "    \"La gratitude multiplie le bonheur.\",\n",
    "    \"La reconnaissance honore les bienfaiteurs.\",\n",
    "    \"L'appr√©ciation valorise les petites choses.\",\n",
    "    \"La mindfulness ancre dans le pr√©sent.\",\n",
    "    \"La s√©r√©nit√© apporte la paix int√©rieure.\",\n",
    "    \"Le calme dans la temp√™te montre la force.\",\n",
    "    \"La r√©silience permet de rebondir.\",\n",
    "    \"L'adaptabilit√© est essentielle au changement.\",\n",
    "    \"La flexibilit√© ouvre de nouvelles voies.\",\n",
    "    \"L'innovation r√©volutionne le monde.\",\n",
    "    \"La cr√©ativit√© n'a pas de limites.\",\n",
    "    \"L'originalit√© distingue les artistes.\",\n",
    "    \"L'audace ouvre des portes.\",\n",
    "    \"Le courage inspire le respect.\",\n",
    "    \"La bravoure face au danger est admirable.\",\n",
    "    \n",
    "    # Phrases sur le temps et les saisons (40 phrases)\n",
    "    \"L'hiver apporte son manteau blanc.\",\n",
    "    \"Le printemps r√©veille la nature endormie.\",\n",
    "    \"L'√©t√© offre ses longues journ√©es ensoleill√©es.\",\n",
    "    \"L'automne peint les for√™ts de couleurs chaudes.\",\n",
    "    \"Les jours rallongent avec le retour du soleil.\",\n",
    "    \"Les nuits se font plus courtes en √©t√©.\",\n",
    "    \"Le temps passe et ne revient jamais.\",\n",
    "    \"Chaque saison a sa beaut√© propre.\",\n",
    "    \"Les ann√©es filent comme le vent.\",\n",
    "    \"Le temps est le plus pr√©cieux des biens.\",\n",
    "    \"L'instant pr√©sent est tout ce que nous avons.\",\n",
    "    \"Le pass√© nous enseigne, le futur nous inspire.\",\n",
    "    \"Aujourd'hui est le premier jour du reste de ta vie.\",\n",
    "    \"Demain est un autre jour.\",\n",
    "    \"Hier est derri√®re nous, demain est un myst√®re.\",\n",
    "    \"Le temps file entre nos doigts.\",\n",
    "    \"Les secondes s'√©gr√®nent inexorablement.\",\n",
    "    \"Les minutes deviennent des heures.\",\n",
    "    \"Les heures se transforment en jours.\",\n",
    "    \"Les jours composent les semaines.\",\n",
    "    \"Les semaines forment les mois.\",\n",
    "    \"Les mois constituent les ann√©es.\",\n",
    "    \"Le temps ne s'arr√™te jamais.\",\n",
    "    \"L'horloge tourne sans rel√¢che.\",\n",
    "    \"Le sablier s'√©coule grain par grain.\",\n",
    "    \"La vie est une course contre le temps.\",\n",
    "    \"Chaque moment compte dans notre existence.\",\n",
    "    \"Le temps perdu ne se rattrape jamais.\",\n",
    "    \"Il faut savoir profiter de l'instant.\",\n",
    "    \"Le moment pr√©sent est un cadeau.\",\n",
    "    \"L'√©ternit√© commence maintenant.\",\n",
    "    \"Le temps r√©v√®le toutes les v√©rit√©s.\",\n",
    "    \"La patience vient avec le temps.\",\n",
    "    \"Les blessures gu√©rissent avec le temps.\",\n",
    "    \"Le temps arrange beaucoup de choses.\",\n",
    "    \"Avec le temps va, tout s'en va.\",\n",
    "    \"Le temps est un grand ma√Ætre.\",\n",
    "    \"La sagesse s'acquiert avec le temps.\",\n",
    "    \"Le temps respecte ce qui est fait avec lui.\",\n",
    "    \"Chaque √¢ge a ses plaisirs et ses peines.\",\n",
    "    \n",
    "    # Phrases sur l'apprentissage et la connaissance (50 phrases)\n",
    "    \"Apprendre, c'est d√©couvrir ce que l'on sait d√©j√†.\",\n",
    "    \"La connaissance est un tr√©sor qui suit son propri√©taire partout.\",\n",
    "    \"Celui qui pose une question reste ignorant cinq minutes.\",\n",
    "    \"Celui qui ne la pose pas reste ignorant toute sa vie.\",\n",
    "    \"L'√©ducation est l'arme la plus puissante pour changer le monde.\",\n",
    "    \"Un livre est un r√™ve que l'on tient entre ses mains.\",\n",
    "    \"La lecture est √† l'esprit ce que l'exercice est au corps.\",\n",
    "    \"Les livres sont les amis les plus silencieux et les plus constants.\",\n",
    "    \"√âtudier sans r√©fl√©chir est vain, r√©fl√©chir sans √©tudier est dangereux.\",\n",
    "    \"L'ignorance est la nuit de l'esprit.\",\n",
    "    \"La curiosit√© est le moteur de l'intelligence.\",\n",
    "    \"Poser des questions est le premier pas vers la sagesse.\",\n",
    "    \"L'apprentissage est un tr√©sor qui suivra partout.\",\n",
    "    \"Plus on apprend, plus on r√©alise qu'on ne sait rien.\",\n",
    "    \"La vraie connaissance commence par la reconnaissance de son ignorance.\",\n",
    "    \"L'exp√©rience est le meilleur des enseignants.\",\n",
    "    \"On apprend de ses erreurs plus que de ses succ√®s.\",\n",
    "    \"Chaque √©chec est une opportunit√© d'apprendre.\",\n",
    "    \"La pratique rend parfait.\",\n",
    "    \"La r√©p√©tition est la m√®re de l'apprentissage.\",\n",
    "    \"Un bon professeur inspire pour l'√©ternit√©.\",\n",
    "    \"Enseigner, c'est apprendre deux fois.\",\n",
    "    \"L'√©cole de la vie n'a pas de vacances.\",\n",
    "    \"On n'a jamais fini d'apprendre.\",\n",
    "    \"La culture est ce qui reste quand on a tout oubli√©.\",\n",
    "    \"L'intelligence n'est pas de savoir beaucoup mais de bien utiliser ce qu'on sait.\",\n",
    "    \"La m√©moire est le gardien du savoir.\",\n",
    "    \"Comprendre, c'est commencer √† √™tre libre.\",\n",
    "    \"Le savoir-faire vaut mieux que le savoir.\",\n",
    "    \"La th√©orie sans la pratique est inutile.\",\n",
    "    \"La pratique sans la th√©orie est aveugle.\",\n",
    "    \"L'analyse critique aiguise l'esprit.\",\n",
    "    \"Le doute est le commencement de la science.\",\n",
    "    \"La science avance par essais et erreurs.\",\n",
    "    \"La recherche est une aventure passionnante.\",\n",
    "    \"La d√©couverte ne consiste pas √† chercher de nouveaux paysages.\",\n",
    "    \"Elle consiste √† avoir de nouveaux yeux.\",\n",
    "    \"L'innovation na√Æt de la combinaison de connaissances.\",\n",
    "    \"Les grands esprits discutent des id√©es.\",\n",
    "    \"Les esprits moyens discutent des √©v√©nements.\",\n",
    "    \"Les petits esprits discutent des personnes.\",\n",
    "    \"La philosophie enseigne √† penser par soi-m√™me.\",\n",
    "    \"La logique est la grammaire de la raison.\",\n",
    "    \"Les math√©matiques sont le langage de l'univers.\",\n",
    "    \"La science est organis√©e connaissance.\",\n",
    "    \"La sagesse est organis√©e vie.\",\n",
    "    \"Le g√©nie est fait de un pour cent d'inspiration.\",\n",
    "    \"Et de quatre-vingt-dix-neuf pour cent de transpiration.\",\n",
    "    \"L'intelligence artificielle commence o√π finit la n√¥tre.\",\n",
    "    \"La technologie devrait simplifier la vie, pas la compliquer.\",\n",
    "]\n",
    "\n",
    "print(f\"üìö Corpus cr√©√© : {len(corpus_francais)} phrases\")\n",
    "print(f\"\\nüìä R√©partition du corpus :\")\n",
    "print(f\"  ‚Ä¢ Proverbes fran√ßais classiques : ~50\")\n",
    "print(f\"  ‚Ä¢ Citations sur la vie : ~60\")\n",
    "print(f\"  ‚Ä¢ Phrases sur la nature : ~50\")\n",
    "print(f\"  ‚Ä¢ Actions et valeurs : ~60\")\n",
    "print(f\"  ‚Ä¢ Temps et saisons : ~40\")\n",
    "print(f\"  ‚Ä¢ Apprentissage et connaissance : ~50\")\n",
    "print(f\"\\nüìù Exemples de phrases :\")\n",
    "for i, phrase in enumerate(corpus_francais[:5], 1):\n",
    "    print(f\"  {i}. {phrase}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing et Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Normalisation du texte fran√ßais\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z√†√¢√§√¶√ß√©√®√™√´√Ø√Æ√¥√π√ª√º√ø≈ì'\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# Preprocessing\n",
    "corpus_cleaned = [preprocess_text(phrase) for phrase in corpus_francais]\n",
    "\n",
    "# Tokenization\n",
    "tokenizer = Tokenizer(char_level=False, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(corpus_cleaned)\n",
    "\n",
    "# Vocabulaire\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "sequences = tokenizer.texts_to_sequences(corpus_cleaned)\n",
    "max_len = max(len(seq) for seq in sequences)\n",
    "\n",
    "print(f\"\\nüìä Statistiques du vocabulaire :\")\n",
    "print(f\"  ‚Ä¢ Taille du vocabulaire : {vocab_size}\")\n",
    "print(f\"  ‚Ä¢ Longueur maximale : {max_len} mots\")\n",
    "print(f\"  ‚Ä¢ Longueur moyenne : {np.mean([len(s) for s in sequences]):.1f} mots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pr√©paration des Donn√©es d'Entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des s√©quences d'entra√Ænement\n",
    "input_sequences = []\n",
    "target_sequences = []\n",
    "\n",
    "for sequence in sequences:\n",
    "    for i in range(1, len(sequence)):\n",
    "        input_seq = sequence[:i]\n",
    "        target_word = sequence[i]\n",
    "        input_sequences.append(input_seq)\n",
    "        target_sequences.append(target_word)\n",
    "\n",
    "# Padding\n",
    "X = pad_sequences(input_sequences, maxlen=max_len-1, padding='pre')\n",
    "y = tf.keras.utils.to_categorical(target_sequences, num_classes=vocab_size)\n",
    "\n",
    "print(f\"\\nüéØ Donn√©es d'entra√Ænement :\")\n",
    "print(f\"  ‚Ä¢ X shape : {X.shape}\")\n",
    "print(f\"  ‚Ä¢ y shape : {y.shape}\")\n",
    "print(f\"  ‚Ä¢ Nombre d'exemples : {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üÜï Warmup Learning Rate Schedule\n",
    "\n",
    "### Concept : Augmentation Progressive du Learning Rate\n",
    "\n",
    "Le **Warmup LR Schedule** est une technique cl√© pour stabiliser l'entra√Ænement des Transformers :\n",
    "\n",
    "#### üìà Phases du Warmup\n",
    "1. **Phase Warmup** (steps 0 ‚Üí warmup_steps) :\n",
    "   - Learning rate augmente lin√©airement de 0 ‚Üí lr_max\n",
    "   - Permet aux gradients de se stabiliser\n",
    "   - √âvite les updates trop agressifs au d√©but\n",
    "\n",
    "2. **Phase Decay** (apr√®s warmup_steps) :\n",
    "   - Learning rate d√©cro√Æt selon une fonction (ici : inverse square root)\n",
    "   - Permet un entrainement progressif\n",
    "\n",
    "#### üéØ Pourquoi c'est important ?\n",
    "- Les Transformers sont **tr√®s sensibles** au LR en d√©but d'entra√Ænement\n",
    "- Sans warmup : risque de **divergence** (loss ‚Üí infinity)\n",
    "- Avec warmup : convergence **stable et rapide**\n",
    "\n",
    "#### üìä Formule Math√©matique\n",
    "```\n",
    "lr(step) = d_model^(-0.5) √ó min(step^(-0.5), step √ó warmup_steps^(-1.5))\n",
    "```\n",
    "\n",
    "**Utilis√© dans :** GPT, BERT, T5, tous les LLMs modernes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmupSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    Learning Rate Schedule avec Warmup\n",
    "    \n",
    "    Inspir√© du papier 'Attention is All You Need'\n",
    "    \n",
    "    Arguments:\n",
    "        d_model: dimension du mod√®le (utilis√© pour normaliser le LR)\n",
    "        warmup_steps: nombre d'√©tapes pour la phase de warmup\n",
    "    \n",
    "    Formule:\n",
    "        lr = d_model^(-0.5) * min(step^(-0.5), step * warmup_steps^(-1.5))\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        \"\"\"\n",
    "        Calcule le learning rate pour un step donn√©\n",
    "        \n",
    "        Phase 1 (Warmup): LR augmente lin√©airement\n",
    "        Phase 2 (Decay): LR d√©cro√Æt selon inverse square root\n",
    "        \"\"\"\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        \n",
    "        # Normalisation par la dimension du mod√®le\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        # Prendre le minimum = warmup lin√©aire puis decay\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"d_model\": int(self.d_model.numpy()),\n",
    "            \"warmup_steps\": self.warmup_steps\n",
    "        }\n",
    "\n",
    "# Visualisation du Schedule\n",
    "def visualize_lr_schedule(d_model=128, warmup_steps=1000, total_steps=10000):\n",
    "    \"\"\"\n",
    "    Visualise l'√©volution du learning rate\n",
    "    \"\"\"\n",
    "    schedule = WarmupSchedule(d_model, warmup_steps)\n",
    "    \n",
    "    steps = np.arange(1, total_steps)\n",
    "    learning_rates = [schedule(step).numpy() for step in steps]\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Graphique principal\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(steps, learning_rates, linewidth=2, color='#3498db')\n",
    "    plt.axvline(x=warmup_steps, color='red', linestyle='--', \n",
    "                label=f'Fin Warmup (step {warmup_steps})', alpha=0.7)\n",
    "    plt.xlabel('Steps', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
    "    plt.title('üìà Warmup Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Zoom sur la phase de warmup\n",
    "    plt.subplot(1, 2, 2)\n",
    "    warmup_region = steps <= warmup_steps * 1.5\n",
    "    plt.plot(steps[warmup_region], np.array(learning_rates)[warmup_region], \n",
    "             linewidth=2, color='#e74c3c')\n",
    "    plt.axvline(x=warmup_steps, color='green', linestyle='--', \n",
    "                label=f'Fin Warmup', alpha=0.7)\n",
    "    plt.xlabel('Steps', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
    "    plt.title('üîç Zoom Phase Warmup', fontsize=14, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Statistiques du Schedule :\")\n",
    "    print(f\"  ‚Ä¢ LR initial (step 1) : {learning_rates[0]:.6f}\")\n",
    "    print(f\"  ‚Ä¢ LR au warmup (step {warmup_steps}) : {learning_rates[warmup_steps-1]:.6f}\")\n",
    "    print(f\"  ‚Ä¢ LR max : {max(learning_rates):.6f}\")\n",
    "    print(f\"  ‚Ä¢ LR final (step {total_steps-1}) : {learning_rates[-1]:.6f}\")\n",
    "\n",
    "# Visualiser le schedule\n",
    "visualize_lr_schedule(d_model=128, warmup_steps=1000, total_steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Architecture Transformer avec Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi-Head Self-Attention Layer\n",
    "    \n",
    "    Permet au mod√®le de regarder diff√©rentes parties de la s√©quence\n",
    "    avec plusieurs \"t√™tes\" d'attention en parall√®le.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        assert d_model % num_heads == 0, \"d_model doit √™tre divisible par num_heads\"\n",
    "        \n",
    "        self.depth = d_model // num_heads\n",
    "        \n",
    "        # Projections lin√©aires pour Q, K, V\n",
    "        self.wq = layers.Dense(d_model)\n",
    "        self.wk = layers.Dense(d_model)\n",
    "        self.wv = layers.Dense(d_model)\n",
    "        \n",
    "        # Projection de sortie\n",
    "        self.dense = layers.Dense(d_model)\n",
    "    \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Divise en t√™tes multiples\"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, x):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        \n",
    "        # Projections lin√©aires\n",
    "        q = self.wq(x)\n",
    "        k = self.wk(x)\n",
    "        v = self.wv(x)\n",
    "        \n",
    "        # Diviser en t√™tes multiples\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "        \n",
    "        # Scaled Dot-Product Attention\n",
    "        matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "        dk = tf.cast(self.depth, tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        \n",
    "        # Causal mask (pour g√©n√©ration autoregressif)\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        mask = tf.reshape(mask, (1, 1, seq_len, seq_len))\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "        \n",
    "        # Recombiner les t√™tes\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(output, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # Projection finale\n",
    "        output = self.dense(concat_attention)\n",
    "        return output\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    Bloc Transformer complet\n",
    "    \n",
    "    Contient:\n",
    "    - Multi-Head Attention\n",
    "    - Feed-Forward Network\n",
    "    - Layer Normalization\n",
    "    - Residual Connections\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Multi-Head Attention\n",
    "        self.attention = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        \n",
    "        # Feed-Forward Network\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(dff, activation='relu'),\n",
    "            layers.Dense(d_model)\n",
    "        ])\n",
    "        \n",
    "        # Layer Normalization\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def call(self, x, training):\n",
    "        # Multi-Head Attention + Residual + LayerNorm\n",
    "        attn_output = self.attention(x)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        # Feed-Forward + Residual + LayerNorm\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        \n",
    "        return out2\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "    \"\"\"\n",
    "    Cr√©e le positional encoding sinuso√Ødal\n",
    "    \"\"\"\n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(depth)[np.newaxis, :] / depth\n",
    "    \n",
    "    angle_rates = 1 / (10000 ** depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.zeros((length, depth))\n",
    "    pos_encoding[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    pos_encoding[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def create_transformer_model(vocab_size, max_len, d_model=128, num_heads=8, \n",
    "                            num_blocks=2, dff=512, dropout_rate=0.1):\n",
    "    \"\"\"\n",
    "    Cr√©e le mod√®le Transformer complet\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(max_len-1,))\n",
    "    \n",
    "    # Embedding + Positional Encoding\n",
    "    x = layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    x = x * tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    pos_encoding = positional_encoding(max_len-1, d_model)\n",
    "    x = x + pos_encoding\n",
    "    \n",
    "    # Transformer Blocks\n",
    "    for _ in range(num_blocks):\n",
    "        x = TransformerBlock(d_model, num_heads, dff, dropout_rate)(x, training=True)\n",
    "    \n",
    "    # Couche de sortie\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Architecture Transformer d√©finie !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cr√©ation et Compilation du Mod√®le avec Warmup LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam√®tres\n",
    "D_MODEL = 128\n",
    "NUM_HEADS = 8\n",
    "NUM_BLOCKS = 2\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "WARMUP_STEPS = 1000\n",
    "\n",
    "# Cr√©ation du mod√®le\n",
    "model = create_transformer_model(\n",
    "    vocab_size=vocab_size,\n",
    "    max_len=max_len,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    dff=DFF,\n",
    "    dropout_rate=DROPOUT\n",
    ")\n",
    "\n",
    "# üÜï Warmup Learning Rate Schedule\n",
    "lr_schedule = WarmupSchedule(d_model=D_MODEL, warmup_steps=WARMUP_STEPS)\n",
    "\n",
    "# Optimizer avec le schedule\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# Compilation\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# R√©sum√©\n",
    "print(f\"\\nüìä Architecture du Mod√®le Transformer :\")\n",
    "print(f\"  ‚Ä¢ Vocabulaire : {vocab_size} mots\")\n",
    "print(f\"  ‚Ä¢ Dimension : {D_MODEL}\")\n",
    "print(f\"  ‚Ä¢ Nombre de t√™tes : {NUM_HEADS}\")\n",
    "print(f\"  ‚Ä¢ Nombre de blocs : {NUM_BLOCKS}\")\n",
    "print(f\"  ‚Ä¢ Feed-Forward dim : {DFF}\")\n",
    "print(f\"  ‚Ä¢ Warmup steps : {WARMUP_STEPS}\")\n",
    "print(f\"\\nüîß Optimizer : Adam avec Warmup LR Schedule\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Entra√Ænement du Mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback pour visualiser le progr√®s\n",
    "class TrainingProgressCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "        self.lrs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.losses.append(logs['loss'])\n",
    "        self.accuracies.append(logs['accuracy'])\n",
    "        \n",
    "        # R√©cup√©rer le learning rate actuel\n",
    "        lr = self.model.optimizer.learning_rate\n",
    "        if isinstance(lr, tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "            step = self.model.optimizer.iterations\n",
    "            lr_value = lr(step).numpy()\n",
    "        else:\n",
    "            lr_value = lr.numpy()\n",
    "        self.lrs.append(lr_value)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"\\nüéØ Epoch {epoch+1}/{EPOCHS}\")\n",
    "            print(f\"  ‚Ä¢ Loss : {logs['loss']:.4f}\")\n",
    "            print(f\"  ‚Ä¢ Accuracy : {logs['accuracy']:.4f}\")\n",
    "            print(f\"  ‚Ä¢ Learning Rate : {lr_value:.6f}\")\n",
    "\n",
    "# Entra√Ænement\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "progress_callback = TrainingProgressCallback()\n",
    "\n",
    "print(\"üöÄ D√©but de l'entra√Ænement...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=0,\n",
    "    callbacks=[progress_callback]\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Entra√Ænement termin√© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualisation des R√©sultats avec Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation compl√®te\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(progress_callback.losses, linewidth=2, color='#e74c3c')\n",
    "axes[0, 0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Loss', fontweight='bold')\n",
    "axes[0, 0].set_title('üìâ Evolution de la Loss', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 1].plot(progress_callback.accuracies, linewidth=2, color='#2ecc71')\n",
    "axes[0, 1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[0, 1].set_title('üìà Evolution de l\\'Accuracy', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[1, 0].plot(progress_callback.lrs, linewidth=2, color='#3498db')\n",
    "axes[1, 0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Learning Rate', fontweight='bold')\n",
    "axes[1, 0].set_title('‚ö° Evolution du Learning Rate (Warmup)', fontweight='bold', fontsize=14)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparaison Loss vs LR\n",
    "ax1 = axes[1, 1]\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "line1 = ax1.plot(progress_callback.losses, linewidth=2, color='#e74c3c', label='Loss')\n",
    "line2 = ax2.plot(progress_callback.lrs, linewidth=2, color='#3498db', label='Learning Rate')\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontweight='bold')\n",
    "ax1.set_ylabel('Loss', fontweight='bold', color='#e74c3c')\n",
    "ax2.set_ylabel('Learning Rate', fontweight='bold', color='#3498db')\n",
    "ax1.set_title('üîÑ Loss vs Learning Rate', fontweight='bold', fontsize=14)\n",
    "\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä R√©sultats Finaux :\")\n",
    "print(f\"  ‚Ä¢ Loss finale : {progress_callback.losses[-1]:.4f}\")\n",
    "print(f\"  ‚Ä¢ Accuracy finale : {progress_callback.accuracies[-1]:.4f}\")\n",
    "print(f\"  ‚Ä¢ Learning Rate final : {progress_callback.lrs[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. üÜï Temperature Tuning : Contr√¥le de la Cr√©ativit√©\n",
    "\n",
    "### Concept : Ajuster la Distribution de Probabilit√©\n",
    "\n",
    "La **Temperature** est un hyperparam√®tre qui contr√¥le la \"cr√©ativit√©\" de la g√©n√©ration :\n",
    "\n",
    "#### üå°Ô∏è Effet de la Temperature\n",
    "\n",
    "**Temperature = 1.0** (neutre)\n",
    "- Probabilit√©s inchang√©es\n",
    "- √âquilibre cr√©ativit√©/coh√©rence\n",
    "\n",
    "**Temperature < 1.0** (conservative : 0.5-0.9)\n",
    "- Accentue les probabilit√©s √©lev√©es\n",
    "- G√©n√©ration plus **d√©terministe** et **coh√©rente**\n",
    "- Moins de diversit√©\n",
    "- ‚úÖ Id√©al pour : textes formels, traduction, code\n",
    "\n",
    "**Temperature > 1.0** (cr√©ative : 1.1-1.5)\n",
    "- Aplatit les probabilit√©s\n",
    "- G√©n√©ration plus **diverse** et **surprenante**\n",
    "- Peut √™tre moins coh√©rente\n",
    "- ‚úÖ Id√©al pour : cr√©ativit√©, brainstorming, fiction\n",
    "\n",
    "#### üìê Formule Math√©matique\n",
    "```\n",
    "P_temp(i) = exp(logits[i] / T) / Œ£ exp(logits[j] / T)\n",
    "```\n",
    "\n",
    "O√π T = temperature\n",
    "\n",
    "#### üéØ Recommandations Pratiques\n",
    "- **0.5-0.7** : R√©ponses factuelles, traduction\n",
    "- **0.8-1.0** : Usage g√©n√©ral\n",
    "- **1.1-1.3** : G√©n√©ration cr√©ative\n",
    "- **1.4-1.5** : Exp√©rimentation, id√©es nouvelles\n",
    "\n",
    "**Utilis√© dans :** ChatGPT, Claude, Gemini (param√®tre ajustable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_temperature(logits, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Applique la temperature aux logits avant softmax\n",
    "    \n",
    "    Arguments:\n",
    "        logits: scores bruts du mod√®le (avant softmax)\n",
    "        temperature: facteur de temp√©rature (0.5-1.5)\n",
    "            - < 1.0 : plus d√©terministe\n",
    "            - = 1.0 : neutre\n",
    "            - > 1.0 : plus cr√©atif\n",
    "    \n",
    "    Returns:\n",
    "        probabilit√©s ajust√©es\n",
    "    \"\"\"\n",
    "    # Diviser les logits par la temp√©rature\n",
    "    scaled_logits = logits / temperature\n",
    "    \n",
    "    # Appliquer softmax pour obtenir les probabilit√©s\n",
    "    probabilities = tf.nn.softmax(scaled_logits)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "def visualize_temperature_effect():\n",
    "    \"\"\"\n",
    "    Visualise l'effet de la temp√©rature sur une distribution\n",
    "    \"\"\"\n",
    "    # Exemple de logits (scores bruts)\n",
    "    logits = np.array([2.0, 1.0, 0.5, 0.2, 0.1])\n",
    "    temperatures = [0.5, 0.8, 1.0, 1.3, 1.5]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, temp in enumerate(temperatures):\n",
    "        probs = apply_temperature(logits, temp).numpy()\n",
    "        \n",
    "        axes[idx].bar(range(len(probs)), probs, color='#3498db', alpha=0.7)\n",
    "        axes[idx].set_title(f'Temperature = {temp}', fontweight='bold', fontsize=12)\n",
    "        axes[idx].set_ylabel('Probabilit√©')\n",
    "        axes[idx].set_xlabel('Token')\n",
    "        axes[idx].set_ylim([0, 1])\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Ajouter les valeurs sur les barres\n",
    "        for i, p in enumerate(probs):\n",
    "            axes[idx].text(i, p + 0.02, f'{p:.2f}', ha='center', fontsize=9)\n",
    "    \n",
    "    # Graphique de synth√®se\n",
    "    axes[5].axis('off')\n",
    "    summary_text = \"\"\"üå°Ô∏è Effet de la Temperature:\n",
    "    \n",
    "T = 0.5  ‚Üí Tr√®s d√©terministe\n",
    "           (top token dominant)\n",
    "    \n",
    "T = 1.0  ‚Üí √âquilibr√©\n",
    "           (distribution originale)\n",
    "    \n",
    "T = 1.5  ‚Üí Tr√®s cr√©atif\n",
    "           (distribution aplatie)\"\"\"\n",
    "    \n",
    "    axes[5].text(0.5, 0.5, summary_text, \n",
    "                transform=axes[5].transAxes,\n",
    "                fontsize=11, verticalalignment='center',\n",
    "                horizontalalignment='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualiser l'effet de la temp√©rature\n",
    "visualize_temperature_effect()\n",
    "\n",
    "print(\"\\n‚úÖ Fonction de Temperature d√©finie !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. üÜï Beam Search : Recherche Sophistiqu√©e\n",
    "\n",
    "### Concept : Explorer Plusieurs Hypoth√®ses en Parall√®le\n",
    "\n",
    "Le **Beam Search** am√©liore la g√©n√©ration en gardant les K meilleurs candidats √† chaque √©tape :\n",
    "\n",
    "#### üîç Comparaison des Strat√©gies\n",
    "\n",
    "**Greedy Search** (baseline)\n",
    "- Choisit toujours le token le plus probable\n",
    "- Rapide mais myope\n",
    "- Peut rater de meilleures s√©quences globales\n",
    "\n",
    "**Beam Search** (am√©lior√©)\n",
    "- Garde K meilleurs chemins (beams) en parall√®le\n",
    "- Score cumul√© : log(P(w1)) + log(P(w2)) + ...\n",
    "- Plus lent mais meilleure qualit√©\n",
    "\n",
    "#### üìä Algorithme\n",
    "```\n",
    "1. Initialiser avec K beams = [mot de d√©part]\n",
    "2. Pour chaque position:\n",
    "   a. Pour chaque beam:\n",
    "      - Pr√©dire probabilit√©s du prochain mot\n",
    "      - Calculer score cumul√©\n",
    "   b. Garder les K meilleurs beams\n",
    "3. Retourner le beam avec le meilleur score total\n",
    "```\n",
    "\n",
    "#### üéØ Param√®tre Cl√© : beam_width\n",
    "- **beam_width = 1** ‚Üí Greedy search (rapide, qualit√© moyenne)\n",
    "- **beam_width = 3-5** ‚Üí Bon compromis qualit√©/vitesse\n",
    "- **beam_width = 10+** ‚Üí Meilleure qualit√©, plus lent\n",
    "\n",
    "#### ‚ö° Normalisation de Longueur\n",
    "On divise le score par la longueur pour ne pas favoriser les s√©quences courtes :\n",
    "```\n",
    "score_normalis√© = score_total / longueur^alpha\n",
    "```\n",
    "o√π alpha ‚âà 0.6-0.7\n",
    "\n",
    "**Utilis√© dans :** Traduction automatique (Google Translate), r√©sum√© de texte, sous-titrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_generate(model, tokenizer, seed_text, num_words, beam_width=5, \n",
    "                        temperature=1.0, length_penalty=0.6):\n",
    "    \"\"\"\n",
    "    G√©n√©ration de texte avec Beam Search\n",
    "    \n",
    "    Arguments:\n",
    "        model: mod√®le entra√Æn√©\n",
    "        tokenizer: tokenizer utilis√©\n",
    "        seed_text: texte de d√©part\n",
    "        num_words: nombre de mots √† g√©n√©rer\n",
    "        beam_width: nombre de beams √† garder (3-10 recommand√©)\n",
    "        temperature: facteur de temp√©rature (0.5-1.5)\n",
    "        length_penalty: p√©nalit√© de longueur (0.5-1.0)\n",
    "            - Plus petit = favorise s√©quences courtes\n",
    "            - Plus grand = favorise s√©quences longues\n",
    "    \n",
    "    Returns:\n",
    "        meilleur texte g√©n√©r√© selon le score beam search\n",
    "    \"\"\"\n",
    "    # Preprocessing du seed\n",
    "    seed_text = preprocess_text(seed_text)\n",
    "    \n",
    "    # Obtenir la longueur d'entr√©e du mod√®le\n",
    "    input_length = model.input_shape[1]\n",
    "    \n",
    "    # Initialiser les beams : [(s√©quence, score)]\n",
    "    # Score = somme des log probabilit√©s\n",
    "    beams = [(seed_text, 0.0)]\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        all_candidates = []\n",
    "        \n",
    "        # Pour chaque beam actuel\n",
    "        for seq, score in beams:\n",
    "            # Pr√©parer l'input\n",
    "            token_list = tokenizer.texts_to_sequences([seq])[0]\n",
    "            token_list = pad_sequences([token_list], maxlen=input_length, padding='pre')\n",
    "            \n",
    "            # Pr√©dire les probabilit√©s\n",
    "            predictions = model.predict(token_list, verbose=0)[0]\n",
    "            \n",
    "            # Appliquer la temp√©rature\n",
    "            predictions = apply_temperature(predictions, temperature).numpy()\n",
    "            \n",
    "            # Obtenir les top-K pr√©dictions\n",
    "            # On prend plus que beam_width pour avoir du choix\n",
    "            top_k = min(beam_width * 2, len(predictions))\n",
    "            top_indices = np.argsort(predictions)[-top_k:]\n",
    "            \n",
    "            # Cr√©er de nouveaux candidats\n",
    "            for idx in top_indices:\n",
    "                # Ignorer le token padding (0)\n",
    "                if idx == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Trouver le mot correspondant\n",
    "                word = \"\"\n",
    "                for w, i in tokenizer.word_index.items():\n",
    "                    if i == idx:\n",
    "                        word = w\n",
    "                        break\n",
    "                \n",
    "                if word:\n",
    "                    # Nouvelle s√©quence\n",
    "                    new_seq = seq + \" \" + word\n",
    "                    \n",
    "                    # Score cumul√© = score pr√©c√©dent + log(probabilit√©)\n",
    "                    # Utiliser log pour √©viter underflow\n",
    "                    new_score = score + np.log(predictions[idx] + 1e-10)\n",
    "                    \n",
    "                    all_candidates.append((new_seq, new_score))\n",
    "        \n",
    "        # Normalisation par la longueur\n",
    "        # Pour ne pas favoriser les s√©quences courtes\n",
    "        def normalized_score(item):\n",
    "            seq, score = item\n",
    "            length = len(seq.split())\n",
    "            return score / (length ** length_penalty)\n",
    "        \n",
    "        # Trier et garder les meilleurs beams\n",
    "        beams = sorted(all_candidates, key=normalized_score, reverse=True)[:beam_width]\n",
    "        \n",
    "        # V√©rifier si tous les beams ont atteint la longueur max\n",
    "        if all(len(seq.split()) >= len(seed_text.split()) + num_words for seq, _ in beams):\n",
    "            break\n",
    "    \n",
    "    # Retourner le meilleur beam\n",
    "    best_sequence = beams[0][0] if beams else seed_text\n",
    "    return best_sequence\n",
    "\n",
    "def greedy_generate(model, tokenizer, seed_text, num_words, temperature=1.0):\n",
    "    \"\"\"\n",
    "    G√©n√©ration greedy (baseline pour comparaison)\n",
    "    Choisit toujours le token le plus probable\n",
    "    \n",
    "    Arguments:\n",
    "        model: mod√®le entra√Æn√©\n",
    "        tokenizer: tokenizer utilis√©\n",
    "        seed_text: texte de d√©part\n",
    "        num_words: nombre de mots √† g√©n√©rer\n",
    "        temperature: facteur de temp√©rature (0.5-1.5)\n",
    "    \"\"\"\n",
    "    seed_text = preprocess_text(seed_text)\n",
    "    generated_text = seed_text\n",
    "    \n",
    "    # Obtenir la longueur d'entr√©e du mod√®le\n",
    "    input_length = model.input_shape[1]\n",
    "    \n",
    "    for _ in range(num_words):\n",
    "        token_list = tokenizer.texts_to_sequences([generated_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=input_length, padding='pre')\n",
    "        \n",
    "        predictions = model.predict(token_list, verbose=0)[0]\n",
    "        predictions = apply_temperature(predictions, temperature).numpy()\n",
    "        \n",
    "        predicted_id = np.argmax(predictions)\n",
    "        \n",
    "        if predicted_id == 0:\n",
    "            break\n",
    "        \n",
    "        predicted_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_id:\n",
    "                predicted_word = word\n",
    "                break\n",
    "        \n",
    "        if not predicted_word:\n",
    "            break\n",
    "        \n",
    "        generated_text += \" \" + predicted_word\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "print(\"‚úÖ Fonctions de g√©n√©ration (Beam Search + Greedy) d√©finies !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Comparaison : Greedy vs Beam Search avec Diff√©rentes Temp√©ratures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeds de test\n",
    "test_seeds = [\n",
    "    \"la vie\",\n",
    "    \"le bonheur\",\n",
    "    \"qui s√®me\",\n",
    "    \"l'amour\"\n",
    "]\n",
    "\n",
    "# Temp√©ratures √† tester\n",
    "temperatures = [0.5, 0.8, 1.0, 1.3, 1.5]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ COMPARAISON : Greedy Search vs Beam Search\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for seed in test_seeds:\n",
    "    print(f\"\\n\\nüå± Seed : \\\"{seed}\\\"\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        print(f\"\\nüå°Ô∏è  Temperature = {temp}\")\n",
    "        \n",
    "        # G√©n√©ration Greedy\n",
    "        greedy_result = greedy_generate(\n",
    "            model, tokenizer, seed, \n",
    "            num_words=15, \n",
    "            temperature=temp\n",
    "        )\n",
    "        \n",
    "        # G√©n√©ration Beam Search\n",
    "        beam_result = beam_search_generate(\n",
    "            model, tokenizer, seed,\n",
    "            num_words=15,\n",
    "            beam_width=5,\n",
    "            temperature=temp\n",
    "        )\n",
    "        \n",
    "        print(f\"  üìç Greedy  : {greedy_result}\")\n",
    "        print(f\"  üîç Beam(5) : {beam_result}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Analyse D√©taill√©e : Impact du Beam Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tester diff√©rents beam widths\n",
    "beam_widths = [1, 3, 5, 7, 10]\n",
    "seed = \"le bonheur\"\n",
    "temp = 1.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"üî¨ ANALYSE : Impact du Beam Width\")\n",
    "print(f\"Seed = \\\"{seed}\\\" | Temperature = {temp}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for bw in beam_widths:\n",
    "    result = beam_search_generate(\n",
    "        model, tokenizer, seed,\n",
    "        num_words=15,\n",
    "        beam_width=bw,\n",
    "        temperature=temp\n",
    "    )\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"\\nüîç Beam Width = {bw:2d}\")\n",
    "    print(f\"   ‚Üí {result}\")\n",
    "\n",
    "# Visualisation de la diversit√©\n",
    "print(\"\\n\\nüìä Analyse de Diversit√© :\")\n",
    "unique_results = len(set(results))\n",
    "print(f\"  ‚Ä¢ Nombre de r√©sultats uniques : {unique_results}/{len(beam_widths)}\")\n",
    "print(f\"  ‚Ä¢ Diversit√© : {unique_results/len(beam_widths)*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Guide Pratique d'Utilisation\n",
    "\n",
    "### üéØ Recommandations par Cas d'Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_html = \"\"\"\n",
    "<div style=\"font-family: Arial, sans-serif; max-width: 1200px; margin: 0 auto;\">\n",
    "    <h2 style=\"color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px;\">üéØ Guide Pratique : Choisir les Bons Param√®tres</h2>\n",
    "    \n",
    "    <div style=\"background: #e8f5e9; padding: 20px; margin: 15px 0; border-radius: 8px; border-left: 5px solid #2ecc71;\">\n",
    "        <h3 style=\"color: #2e7d32; margin-top: 0;\">üìù G√©n√©ration de Texte Formel</h3>\n",
    "        <p><strong>Cas d'usage :</strong> Rapports, emails professionnels, documentation</p>\n",
    "        <ul>\n",
    "            <li><strong>Temperature :</strong> 0.5 - 0.7 (d√©terministe)</li>\n",
    "            <li><strong>Beam Width :</strong> 5 - 7 (exploration mod√©r√©e)</li>\n",
    "            <li><strong>Length Penalty :</strong> 0.6 - 0.7 (favorise compl√©tude)</li>\n",
    "        </ul>\n",
    "        <div style=\"background: white; padding: 10px; margin-top: 10px; border-radius: 5px; font-family: monospace;\">\n",
    "            <code>beam_search_generate(model, tokenizer, \"le rapport\", num_words=20, beam_width=5, temperature=0.6)</code>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background: #fff3e0; padding: 20px; margin: 15px 0; border-radius: 8px; border-left: 5px solid #f39c12;\">\n",
    "        <h3 style=\"color: #e67e22; margin-top: 0;\">üé® G√©n√©ration Cr√©ative</h3>\n",
    "        <p><strong>Cas d'usage :</strong> Po√©sie, fiction, brainstorming</p>\n",
    "        <ul>\n",
    "            <li><strong>Temperature :</strong> 1.2 - 1.5 (cr√©atif)</li>\n",
    "            <li><strong>Beam Width :</strong> 3 - 5 (diversit√© √©lev√©e)</li>\n",
    "            <li><strong>Length Penalty :</strong> 0.5 - 0.6 (plus libre)</li>\n",
    "        </ul>\n",
    "        <div style=\"background: white; padding: 10px; margin-top: 10px; border-radius: 5px; font-family: monospace;\">\n",
    "            <code>beam_search_generate(model, tokenizer, \"r√™ve\", num_words=25, beam_width=3, temperature=1.3)</code>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background: #e3f2fd; padding: 20px; margin: 15px 0; border-radius: 8px; border-left: 5px solid #2196f3;\">\n",
    "        <h3 style=\"color: #1976d2; margin-top: 0;\">‚öñÔ∏è Usage G√©n√©ral</h3>\n",
    "        <p><strong>Cas d'usage :</strong> G√©n√©ration polyvalente, chatbot</p>\n",
    "        <ul>\n",
    "            <li><strong>Temperature :</strong> 0.8 - 1.0 (√©quilibr√©)</li>\n",
    "            <li><strong>Beam Width :</strong> 5 (bon compromis)</li>\n",
    "            <li><strong>Length Penalty :</strong> 0.6 (standard)</li>\n",
    "        </ul>\n",
    "        <div style=\"background: white; padding: 10px; margin-top: 10px; border-radius: 5px; font-family: monospace;\">\n",
    "            <code>beam_search_generate(model, tokenizer, \"bonjour\", num_words=15, beam_width=5, temperature=0.9)</code>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background: #f3e5f5; padding: 20px; margin: 15px 0; border-radius: 8px; border-left: 5px solid #9c27b0;\">\n",
    "        <h3 style=\"color: #7b1fa2; margin-top: 0;\">üèÉ G√©n√©ration Rapide</h3>\n",
    "        <p><strong>Cas d'usage :</strong> Autocompl√©tion, suggestions en temps r√©el</p>\n",
    "        <ul>\n",
    "            <li><strong>Temperature :</strong> 0.8 (l√©g√®rement d√©terministe)</li>\n",
    "            <li><strong>Beam Width :</strong> 1 (greedy = plus rapide)</li>\n",
    "            <li><strong>M√©thode :</strong> Utiliser greedy_generate()</li>\n",
    "        </ul>\n",
    "        <div style=\"background: white; padding: 10px; margin-top: 10px; border-radius: 5px; font-family: monospace;\">\n",
    "            <code>greedy_generate(model, tokenizer, \"la vie\", num_words=10, temperature=0.8)</code>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background: #ffebee; padding: 20px; margin: 15px 0; border-radius: 8px; border-left: 5px solid #e74c3c;\">\n",
    "        <h3 style=\"color: #c0392b; margin-top: 0;\">‚ö†Ô∏è Conseils Importants</h3>\n",
    "        <ul>\n",
    "            <li>üî• <strong>Temp√©rature trop basse (&lt; 0.3)</strong> : Texte r√©p√©titif et ennuyeux</li>\n",
    "            <li>üå™Ô∏è <strong>Temp√©rature trop haute (&gt; 1.5)</strong> : Texte incoh√©rent et chaotique</li>\n",
    "            <li>üêå <strong>Beam Width trop grand (&gt; 10)</strong> : Tr√®s lent, rendements d√©croissants</li>\n",
    "            <li>‚ö° <strong>Beam Width = 1</strong> : √âquivalent √† Greedy (rapide mais qualit√© moindre)</li>\n",
    "            <li>üìè <strong>Length Penalty</strong> : Ajuster selon longueur d√©sir√©e (0.5-0.8)</li>\n",
    "        </ul>\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"background: #fff9c4; padding: 20px; margin: 15px 0; border-radius: 8px; border-left: 5px solid #ffc107;\">\n",
    "        <h3 style=\"color: #f57f17; margin-top: 0;\">üí° Astuces Avanc√©es</h3>\n",
    "        <ol>\n",
    "            <li><strong>A/B Testing :</strong> G√©n√©rer plusieurs versions et choisir la meilleure</li>\n",
    "            <li><strong>Temperature Scheduling :</strong> Commencer haut (1.2) puis baisser (0.8) pour plus de coh√©rence</li>\n",
    "            <li><strong>Beam Diversity :</strong> Augmenter beam_width quand r√©sultats trop similaires</li>\n",
    "            <li><strong>Early Stopping :</strong> Arr√™ter si le mod√®le g√©n√®re des tokens de ponctuation finale</li>\n",
    "            <li><strong>Post-Processing :</strong> Filtrer les r√©p√©titions ou textes inappropri√©s</li>\n",
    "        </ol>\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(recommendations_html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Playground Interactif : Tester Vos Propres Param√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_generation(seed_text, method='beam', beam_width=5, \n",
    "                          temperature=1.0, num_words=15):\n",
    "    \"\"\"\n",
    "    Fonction interactive pour exp√©rimenter avec les param√®tres\n",
    "    \n",
    "    Arguments:\n",
    "        seed_text: texte de d√©part\n",
    "        method: 'beam' ou 'greedy'\n",
    "        beam_width: largeur du beam (si method='beam')\n",
    "        temperature: temp√©rature (0.5-1.5)\n",
    "        num_words: nombre de mots √† g√©n√©rer\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéÆ PLAYGROUND INTERACTIF\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\n‚öôÔ∏è  Param√®tres :\")\n",
    "    print(f\"   ‚Ä¢ Seed : \\\"{seed_text}\\\"\")\n",
    "    print(f\"   ‚Ä¢ M√©thode : {method.upper()}\")\n",
    "    if method == 'beam':\n",
    "        print(f\"   ‚Ä¢ Beam Width : {beam_width}\")\n",
    "    print(f\"   ‚Ä¢ Temperature : {temperature}\")\n",
    "    print(f\"   ‚Ä¢ Num Words : {num_words}\")\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    \n",
    "    if method == 'beam':\n",
    "        result = beam_search_generate(\n",
    "            model, tokenizer, seed_text,\n",
    "            num_words=num_words,\n",
    "            beam_width=beam_width,\n",
    "            temperature=temperature\n",
    "        )\n",
    "    else:\n",
    "        result = greedy_generate(\n",
    "            model, tokenizer, seed_text,\n",
    "            num_words=num_words,\n",
    "            temperature=temperature\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nüìù R√©sultat :\")\n",
    "    print(f\"   {result}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Exemples d'utilisation\n",
    "print(\"\\nüéØ Exemple 1 : G√©n√©ration Formelle (Conservative)\")\n",
    "interactive_generation(\n",
    "    seed_text=\"le travail\",\n",
    "    method='beam',\n",
    "    beam_width=7,\n",
    "    temperature=0.6,\n",
    "    num_words=15\n",
    ")\n",
    "\n",
    "print(\"\\n\\nüéØ Exemple 2 : G√©n√©ration Cr√©ative\")\n",
    "interactive_generation(\n",
    "    seed_text=\"le r√™ve\",\n",
    "    method='beam',\n",
    "    beam_width=3,\n",
    "    temperature=1.4,\n",
    "    num_words=20\n",
    ")\n",
    "\n",
    "print(\"\\n\\nüéØ Exemple 3 : G√©n√©ration Rapide (Greedy)\")\n",
    "interactive_generation(\n",
    "    seed_text=\"bonjour\",\n",
    "    method='greedy',\n",
    "    temperature=0.8,\n",
    "    num_words=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Visualisation Comparative des M√©thodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Comparaison de performance\n",
    "def compare_methods_performance(seed_text=\"la vie\", num_words=15):\n",
    "    \"\"\"\n",
    "    Compare vitesse et qualit√© des diff√©rentes m√©thodes\n",
    "    \"\"\"\n",
    "    configurations = [\n",
    "        ('Greedy T=0.8', 'greedy', 1, 0.8),\n",
    "        ('Beam(3) T=0.8', 'beam', 3, 0.8),\n",
    "        ('Beam(5) T=1.0', 'beam', 5, 1.0),\n",
    "        ('Beam(7) T=0.6', 'beam', 7, 0.6),\n",
    "        ('Beam(10) T=1.2', 'beam', 10, 1.2),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    times = []\n",
    "    \n",
    "    print(f\"\\nüî¨ Comparaison de Performance pour: \\\"{seed_text}\\\"\\n\")\n",
    "    \n",
    "    for name, method, beam_width, temp in configurations:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if method == 'greedy':\n",
    "            result = greedy_generate(model, tokenizer, seed_text, num_words, temp)\n",
    "        else:\n",
    "            result = beam_search_generate(model, tokenizer, seed_text, num_words, \n",
    "                                         beam_width, temp)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        results.append(result)\n",
    "        times.append(elapsed)\n",
    "        \n",
    "        print(f\"{name:20s} | Temps: {elapsed:6.3f}s | R√©sultat: {result}\")\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Temps d'ex√©cution\n",
    "    names = [c[0] for c in configurations]\n",
    "    colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n",
    "    \n",
    "    ax1.barh(names, times, color=colors, alpha=0.7)\n",
    "    ax1.set_xlabel('Temps (secondes)', fontweight='bold')\n",
    "    ax1.set_title('‚è±Ô∏è Temps d\\'Ex√©cution par M√©thode', fontweight='bold', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Longueur des r√©sultats\n",
    "    lengths = [len(r.split()) for r in results]\n",
    "    ax2.barh(names, lengths, color=colors, alpha=0.7)\n",
    "    ax2.set_xlabel('Nombre de mots', fontweight='bold')\n",
    "    ax2.set_title('üìè Longueur des Textes G√©n√©r√©s', fontweight='bold', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Statistiques :\")\n",
    "    print(f\"  ‚Ä¢ M√©thode la plus rapide : {names[np.argmin(times)]} ({min(times):.3f}s)\")\n",
    "    print(f\"  ‚Ä¢ M√©thode la plus lente : {names[np.argmax(times)]} ({max(times):.3f}s)\")\n",
    "    print(f\"  ‚Ä¢ Rapport vitesse : {max(times)/min(times):.1f}x\")\n",
    "\n",
    "compare_methods_performance(\"le bonheur\", 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Conclusion et R√©capitulatif\n",
    "\n",
    "### üéâ F√©licitations ! Vous avez impl√©ment√© 3 techniques avanc√©es de g√©n√©ration !\n",
    "\n",
    "#### 1. ‚ö° Warmup Learning Rate Schedule\n",
    "**Ce que vous avez appris :**\n",
    "- Augmentation progressive du LR pour stabiliser l'entra√Ænement\n",
    "- Formule : `lr = d_model^(-0.5) √ó min(step^(-0.5), step √ó warmup^(-1.5))`\n",
    "- √âvite la divergence en d√©but d'entra√Ænement\n",
    "- Utilis√© dans **tous les Transformers modernes**\n",
    "\n",
    "**Impact mesur√© :**\n",
    "- ‚úÖ Convergence plus stable\n",
    "- ‚úÖ Meilleure performance finale\n",
    "- ‚úÖ Moins de risque de divergence\n",
    "\n",
    "#### 2. üîç Beam Search\n",
    "**Ce que vous avez appris :**\n",
    "- Exploration de K hypoth√®ses en parall√®le\n",
    "- Score cumul√© avec normalisation de longueur\n",
    "- Meilleure qualit√© que Greedy Search\n",
    "- Utilis√© dans **traduction automatique, r√©sum√©**\n",
    "\n",
    "**Impact mesur√© :**\n",
    "- ‚úÖ G√©n√©ration de meilleure qualit√©\n",
    "- ‚úÖ Plus de coh√©rence globale\n",
    "- ‚ö†Ô∏è Plus lent que Greedy (compromis qualit√©/vitesse)\n",
    "\n",
    "#### 3. üå°Ô∏è Temperature Tuning\n",
    "**Ce que vous avez appris :**\n",
    "- Contr√¥le de la \"cr√©ativit√©\" via ajustement des probabilit√©s\n",
    "- T < 1.0 ‚Üí D√©terministe, T > 1.0 ‚Üí Cr√©atif\n",
    "- Formule : `P_temp(i) = exp(logits[i] / T) / Œ£ exp(logits[j] / T)`\n",
    "- Utilis√© dans **ChatGPT, Claude, Gemini**\n",
    "\n",
    "**Impact mesur√© :**\n",
    "- ‚úÖ Contr√¥le fin de la g√©n√©ration\n",
    "- ‚úÖ Adaptation au cas d'usage\n",
    "- ‚úÖ 0.5-0.7 = formel, 1.2-1.5 = cr√©atif\n",
    "\n",
    "### üìä Tableau Comparatif Final\n",
    "\n",
    "| Crit√®re | Greedy | Beam Search | + Temperature |\n",
    "|---------|--------|-------------|---------------|\n",
    "| Qualit√© | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| Vitesse | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |\n",
    "| Diversit√© | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| Contr√¥le | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |\n",
    "| Complexit√© | Simple | Moyen | Moyen |\n",
    "\n",
    "### üöÄ Prochaines √âtapes\n",
    "\n",
    "**Pour aller plus loin :**\n",
    "1. **Top-p (Nucleus) Sampling** - Alternative au beam search\n",
    "2. **Top-k Sampling** - Limiter aux k tokens les plus probables\n",
    "3. **Diverse Beam Search** - Forcer la diversit√© entre beams\n",
    "4. **Constrained Decoding** - Respecter des contraintes (longueur, mots-cl√©s)\n",
    "5. **Pre-training** - Utiliser des mod√®les pr√©-entra√Æn√©s (CamemBERT)\n",
    "\n",
    "### üí° Message Final\n",
    "\n",
    "Ces trois techniques sont **essentielles** pour obtenir des g√©n√©rations de qualit√© production :\n",
    "- **Warmup LR** ‚Üí Entra√Ænement stable\n",
    "- **Beam Search** ‚Üí G√©n√©ration optimale\n",
    "- **Temperature** ‚Üí Contr√¥le cr√©ativit√©\n",
    "\n",
    "Elles sont utilis√©es dans **TOUS les LLMs modernes** : GPT-4, Claude, Gemini, LLaMA, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
